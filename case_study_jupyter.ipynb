{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the main focus on this project will be to showcase the ability to data clean and do eda using the pandas package with also some data visualization\n",
    "#included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0bbfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will first import pandas package which will be mainly used throughout this project for data cleaning and exploration\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we import the csv file of the dataset into an appropriately named variables \"jobs\" for this project\n",
    "jobs = pd.read_csv(\"Uncleaned_DS_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make sure it is in a dataframe format\n",
    "jobs = pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the columns and their data types we are working with. We can also see that there is no null values. \n",
    "#I also notice that the columns need a little more cleaning and change to snake based format\n",
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958cc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to change the columns to a snake based format we use a lambda function to eventually change them to more appropriate names\n",
    "jobs.rename(columns= lambda header: header.lower().replace(\" \",\"_\"), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we should make sure it works\n",
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now check the first 10 columns using the head column to see what are some immediate shown problems\n",
    "\"\"\"We see some things that may need cleaning straight off the beggining such as deletion of the index column and investigate the competitors.\n",
    "It may be deleted depending on the number of values with responses \"\"\"\n",
    "jobs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will delet the index columns since they are a duplicate of the index seen in vs code\n",
    "jobs.drop(columns=\"index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the index column is not there no more index column\n",
    "jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now have to investigate the abundance of -1 in the competitors column. What percentage makes up the whole column and how many there are\n",
    "jobs.loc[jobs[\"competitors\"] == \"-1\",\"competitors\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the percentage of the value -1 in the column\n",
    "round((501/672 * 100),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is 501 instances of -1 in the making up 75 percent of the column so it is best to drop the column since it is mainly made up of nulls\n",
    "jobs.drop(columns=\"competitors\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c760bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check if it worked again\n",
    "jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column by columns to see if anything shoul be cleaned. First 100 rows should be good for a check up \n",
    "jobs[\"job_title\"][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8365b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"I ran into a problem where there are some parenthesis with random words and numbers in some but some have Sr in them or relevant information\n",
    "so we have to be careful. first we should do is check for all the values in the dataset that have parenthesis to determin which\n",
    "have important information and whcich to delete\"\"\"\n",
    "jobs.loc[jobs[\"job_title\"].str.contains('\\([^()]+\\)'), [\"job_title\",\"company_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e94d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"After further analysis I can conclude that the information in the parenthesis is information that should be in the job_description column\n",
    "the only exception should be the one containing Sr. which just should delete the parenthesis for the title.\n",
    "only solution can be use the replace function for the specific case while deleting the rest of the parenthesis and meanwhile converting\n",
    " every title to lowercase to make a more consistent format\"\"\"\n",
    "\n",
    "#we should replace (Sr.) to Sr. \n",
    "jobs[\"job_title\"]=jobs.loc[:,\"job_title\"].str.replace(\"(Sr.)\",\"Sr.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52049cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the rest of the instances with parenthesis\n",
    "jobs[\"job_title\"]=jobs.loc[:,\"job_title\"].str.extract('([^()]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to follow consistency we should lower all of the values in a column\n",
    "jobs[\"job_title\"]=jobs.loc[:,\"job_title\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is any  instance of parenthesis left\n",
    "jobs.loc[jobs[\"job_title\"].str.contains('\\([^()]+\\)'), [\"job_title\",\"company_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the second column to see if there any data cleaning left to do in the second column\n",
    "\"\"\"What I caught was instances of (Glassdoor est.) in all the columns\"\"\"\n",
    "jobs[\"salary_estimate\"][500:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c799e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We delete the instances using the previous method in the job title and check if it worked\n",
    "jobs[\"salary_estimate\"]=jobs.loc[:,\"salary_estimate\"].str.extract('([^()]+)')\n",
    "jobs[\"salary_estimate\"][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check the third column. This is a column that may need to be checked. Nothing seems to be wrong not even signs of the -1 null value\n",
    "jobs.loc[:,\"job_description\"]\n",
    "jobs.loc[jobs.loc[:,\"job_description\"]==\"-1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the ratings column for any inconsitency. and also null values(-1) which also is empty \n",
    "jobs.loc[:,\"rating\"][:100]\n",
    "jobs.loc[jobs.loc[:,\"rating\"]==\"-1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829258f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check the company name columns and see that the ratings are stuck next to them in the right side with a delimiter of \"\\n\"\n",
    "jobs.loc[:,\"company_name\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use extract to delete eveything after \"\\n\". The regex = true being used to indicate that the pattern is a regulary expression\n",
    "jobs[\"company_name\"]=jobs.loc[:,\"company_name\"].str.replace(r\"\\n\\d+(\\.\\d+)?\",\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check the first 10 columns to see if it works and it does\n",
    "jobs[\"company_name\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the location column now. We can see that there is some inconsitincies with the data . Some values are \"remote\" and some are just the state and even one occasion the country\n",
    "jobs.loc[:,\"location\"][300:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A solution that can be done is split the column into 3 parts being state location, city location and possibly even location country while also making a dummy variable \n",
    "column or section for remote. For this specific project it is assumed all the locations besides remote are in the united states taking a glance at the results \"\"\"\n",
    "jobs.loc[jobs.loc[:,\"location\"]==\"United States\",\"location\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deacf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.loc[jobs.loc[:,\"location\"]==\"Remote\",\"location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0053a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see if there is any other unique values for state that we mightve missed. We can see that there are some hidden ones with the names of the city instead\n",
    "#their respective state initials(New_Jersey,Utah,Texas,California) we can use replace to change to their values using a lambda function\n",
    "jobs.loc[:,\"location\"].apply(lambda x: x.split(\",\")[-1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use the same lambda function to get the state initials and outliers to a new columns and then replace the values with their repective \n",
    "#state initials\n",
    "jobs[\"location_state\"] = jobs.loc[:,\"location\"].apply(lambda x: x.split(\",\")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it worked and it did now we do the same with the city and change the indexing to 0 to get the state half\n",
    "\"\"\"Another issue arises where the same states from the previous lines appears the same states which we will switch to n/a values\n",
    "but first it is better to change the state first\"\"\"\n",
    "jobs[\"location_city\"] = jobs.loc[:,\"location\"].apply(lambda x: x.split(\",\")[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the state names for their respective initials or code names. first we check the values we will replace\n",
    "jobs[\"location_state\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53074573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will create a functions with the specific state codes then use it in the column\n",
    "def clean_city(jobs):\n",
    "    return (\n",
    "        jobs.loc[:, \"location_state\"]\n",
    "        .replace(\"California\",\"CA\")\n",
    "        .replace(\"Texas\",\"TX\")\n",
    "        .replace(\"Utah\",\"UT\")\n",
    "        .replace(\"New Jersey\",\"NJ\")\n",
    "        .replace(\"Remote\",\"n/a\")\n",
    "        .replace(\"United States\",\"n/a\")\n",
    "    )\n",
    "\n",
    "jobs = jobs.assign(\n",
    "    location_state = clean_city\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column to see if the location is in the U.S using boolean values. mainly to distinguish between remote and hybrid/on location\n",
    "jobs[\"location_in_us\"] = jobs.loc[:,\"location\"].apply(lambda x: 1 if x != \"Remote\" else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we see if it works by printing the results of value_counts before and after the created function and it does works!\n",
    "jobs[\"location_state\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we clean the location city but every non city is now \"n/a\"\n",
    "def clean_city(jobs):\n",
    "    return (\n",
    "        jobs.loc[:, \"location_city\"]\n",
    "        .replace(\"California\",\"n/a\")\n",
    "        .replace(\"Texas\",\"n/a\")\n",
    "        .replace(\"Utah\",\"n/a\")\n",
    "        .replace(\"New Jersey\",\"n/a\")\n",
    "        .replace(\"Remote\",\"n/a\")\n",
    "        .replace(\"United States\",\"n/a\")\n",
    "    )\n",
    "\n",
    "jobs = jobs.assign(\n",
    "    location_city = clean_city\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1456e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scimming carefully we can see that it worked with 16 \"n/a values\"\n",
    "jobs[\"location_city\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18177d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what columns we have left to clean and overall column numbers\n",
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59faf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we check the headquarters location unique values. Here we can see that the majority of headquarters locations are the same as the location\n",
    "jobs[\"headquarters\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will use dummy variable labels for location that matches the headquarters location. 1 if they match and 0 if they dont\n",
    "jobs[\"same_location\"] = jobs.apply(lambda x: 1 if x.location == x.headquarters else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ffa234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it worked for safe measure\n",
    "jobs[\"same_location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa274b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we check the company size. Furst thing that we can notice is the repetetive \"employees at every column value\". when we use unique we can\n",
    "#see that there is also -1 and unknonw values, we can replace those to use as \"n/a\" and have them together rather than seperate\n",
    "jobs[\"size\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd34951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first thing should be to remove all the intances of employees with replace and -1, and unknown in some lines of code\n",
    "\"\"\"instead of creating 3 seperate lines of code we can instead create a function to do everything we want in a single line\"\"\"\n",
    "def size_cleaning(jobs):\n",
    "    return (\n",
    "        jobs.loc[:, \"size\"]\n",
    "        .replace(\"employees\",\"\")\n",
    "        .replace(\"-1\",\"n/a\")\n",
    "        .replace(\"Unknown\",\"n/a\")\n",
    "    )\n",
    "\n",
    "jobs = jobs.assign(\n",
    "    size = size_cleaning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check if the function worked and it did \n",
    "jobs[\"size\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590207f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is something worng with the next column and there isnt but we don't neccesarily need the founded column so we will drop it \n",
    "#explanation: we won't need it due to the abundance of -1 in the column and it wouldn't really add much unless we have a specific question regarding competetors\n",
    "jobs[\"founded\"][:100]\n",
    "jobs.drop(columns=\"founded\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac91878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the type of ownership column\n",
    "jobs.loc[:,\"type_of_ownership\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here we can see that there is some weird format that we can change such as nonprofit organization to just nonprofit and company-public to\n",
    "just public company while changin -1 and unknown to n/a and other simplifications for the column in a function\"\"\"\n",
    "\n",
    "def ownership(jobs):\n",
    "    return (\n",
    "        jobs.loc[:, \"type_of_ownership\"]\n",
    "        .replace(\"Nonprofit Organization\",\"Nonprofit\")\n",
    "        .replace(\"-1\",\"n/a\")\n",
    "        .replace(\"Unknown\",\"n/a\")\n",
    "        .replace(\"Company - Public\",\"Public\")\n",
    "        .replace(\"Company - Private\",\"Private\")\n",
    "        .replace(\"Other Organization\",\"Other\")   \n",
    "    )\n",
    "\n",
    "jobs = jobs.assign(\n",
    "    type_of_ownership = ownership\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it works and it does\n",
    "jobs.loc[:,\"type_of_ownership\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655912e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now check the industry column unique values\n",
    "jobs[\"industry\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10bdf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"From using unique and value counts we can see that there is an a good amount of -1 values making it the most values and that can be solved\n",
    "quickly using a lambda function\"\"\"\n",
    "jobs[\"industry\"] = jobs[\"industry\"].apply(lambda x: x.replace(\"-1\",\"n/a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31643e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check value counts to see if it worked \n",
    "jobs[\"industry\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the sector column and their unique values which can be seen to have around 20\n",
    "jobs[\"sector\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e7ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"checking value counts we can see that there is some -1 values, while the other values seem to be looking fine. for this we can use \n",
    "the lambda function from the previous \"\"\"\n",
    "jobs[\"sector\"].value_counts()\n",
    "jobs[\"sector\"] = jobs[\"sector\"].apply(lambda x: x.replace(\"-1\",\"n/a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it worked\n",
    "jobs[\"sector\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fba44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check the revenue\n",
    "jobs[\"revenue\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabee181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here we can combine the unknown value and -1 to n/a values in a function. we overall leabe it alone to not create uneccessary columns and again\n",
    "won't be needed to modyify unless we will need it for a specific problem\"\"\"\n",
    "def revenue_cleanup(jobs):\n",
    "    return (\n",
    "        jobs.loc[:, \"revenue\"]\n",
    "        .replace(\"-1\",\"n/a\")\n",
    "        .replace(\"Unknown / Non-Applicable\",\"n/a\")\n",
    "    )\n",
    "\n",
    "jobs = jobs.assign(\n",
    "    revenue = revenue_cleanup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2898a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check that we have (usd) in the columns so we must use the extract function with the lambda function to get rid of all parenthesis\n",
    "#then we check if it worked\n",
    "jobs[\"revenue\"].value_counts()\n",
    "jobs[\"revenue\"]=jobs.loc[:,\"revenue\"].str.extract('([^()]+)')\n",
    "jobs[\"revenue\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we use jobs to check if there still any instance of -1 in the whole dataframe. we can see that the headquarters we forgot to delete the \n",
    "#instances of -1 in the data frame\n",
    "jobs[jobs.eq(\"-1\").any(axis = 1)]\n",
    "jobs.loc[:,\"headquarters\"][154]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a91fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is multiple -1 values in the headquarters column which we can get rid of with the lambda function\n",
    "jobs.loc[jobs[\"headquarters\"] == \"-1\",\"headquarters\"].value_counts()\n",
    "\n",
    "#we will use the lambda function to change -1 to n/a in the headquarters column\n",
    "jobs[\"headquarters\"] = jobs[\"headquarters\"].apply(lambda x: x.replace(\"-1\",\"n/a\"))\n",
    "\n",
    "#we will see if it worked \n",
    "jobs[\"headquarters\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40cb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will go check if there is -1 value left and there isn't\n",
    "jobs[jobs.eq(\"-1\").any(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf427f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For the salary estimate we can split them both into 3 new columns using the lowest salary, highest and average salary\n",
    "getting rid of the k and $ in the parts to do further analysis and for data visualization. we should check the overall structure by checking the\n",
    "first 10 columns\"\"\"\n",
    "jobs[\"salary_estimate\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a custom function we can use to get rid of the \"k\" and \"$\" and extract the partswhile also turning the column to numeric all in a couple \n",
    "#of lines of code for the lower salary\n",
    "jobs[\"lower_salary\"] = jobs.loc[:,\"salary_estimate\"].apply(lambda x: x.split(\"-\")[0].strip())\n",
    "\n",
    "def lower_salary_clean(jobs):\n",
    "    return pd.to_numeric(\n",
    "        jobs.loc[:, \"lower_salary\"]\n",
    "        .str.replace(\"$\",\"\")\n",
    "        .str.replace(\"K\",\"\")\n",
    "    )\n",
    "jobs = jobs.assign(\n",
    "    lower_salary = lower_salary_clean\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if all is good using the unique value and it does \n",
    "jobs[\"lower_salary\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same exact for the highest potential salary\n",
    "jobs[\"highest_salary\"] = jobs.loc[:,\"salary_estimate\"].apply(lambda x: x.split(\"-\")[-1].strip())\n",
    "\n",
    "def upper_salary_clean(jobs):\n",
    "    return pd.to_numeric(\n",
    "        jobs.loc[:, \"highest_salary\"]\n",
    "        .str.replace(\"$\",\"\")\n",
    "        .str.replace(\"K\",\"\")\n",
    "    )\n",
    "jobs = jobs.assign(\n",
    "    highest_salary = upper_salary_clean\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd37c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it worked and it did\n",
    "jobs[\"highest_salary\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the highest and lowest possible salary to get the average salary of the job \n",
    "jobs[\"average_salary\"] = (jobs[\"highest_salary\"] + jobs[\"lower_salary\"]) //2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it worked\n",
    "jobs[\"average_salary\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fad605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see a 43 so we check if everyhing is good and normal which it is\n",
    "jobs.loc[jobs.loc[:,\"average_salary\"]== 43,\"average_salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91654fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Now we will make a column called job_simp for simplification of the job meaning if they had specific words they would be simplified\n",
    "to a specific title\"\"\"\n",
    "#first we must check what are the most prevelant in the given job titles and from there check which are the data related jobs we want\n",
    "jobs[\"job_title\"].value_counts()\n",
    "\n",
    "def title_simplification(title):\n",
    "    if \"data scientist\" in title.lower():\n",
    "        return \"data scientist\"\n",
    "    elif \"data analyst\" in title.lower():\n",
    "        return \"data analyst\"\n",
    "    elif \"data engineer\" in title.lower():\n",
    "        return \"data engineer\"\n",
    "    elif \"machine learning\" in title.lower():\n",
    "        return \"machine learning\"\n",
    "    elif \"analyst\" in title.lower():\n",
    "        return \"data analyst\"\n",
    "    else:\n",
    "        return \"n/a\"\n",
    "\n",
    "#we then apply the function to the column and checj the unique values  \n",
    "jobs[\"job_simp\"]= jobs[\"job_title\"].apply(title_simplification)\n",
    "jobs[\"job_simp\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10530c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when skimming earlier I saw a good amount of senior, sr. titles in the job titles which can be for more senior position\n",
    "#we can use the previous function method to distinguish titles in the job using key words\n",
    "def title_position(title):\n",
    "    if \"jr.\" in title.lower():\n",
    "        return \"jr\"\n",
    "    elif \"sr\" in title.lower():\n",
    "        return \"sr\"\n",
    "    elif \"sr.\" in title.lower():\n",
    "        return \"sr\"\n",
    "    elif \"vp\" in title.lower():\n",
    "        return \"sr\"\n",
    "    else:\n",
    "        return \"n/a\"\n",
    "    \n",
    "\n",
    "jobs[\"job_position\"]= jobs[\"job_title\"].apply(title_position)   \n",
    "\n",
    "jobs[\"job_position\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all we have left to do is for search of the most popular skills in the description bar such as python, excel,tableau,power bi\n",
    "#we can do this by storing them into dummy variable format where 1 is if the word if founded in the description\n",
    "jobs[\"python\"] = jobs.apply(lambda x: 1 if \"python\" in x.job_description.lower() else 0, axis= 1)\n",
    "jobs[\"excel\"] = jobs.apply(lambda x: 1 if \"excel\" in x.job_description.lower() else 0, axis= 1)\n",
    "jobs[\"tableau\"] = jobs.apply(lambda x: 1 if \"tableau\" in x.job_description.lower() else 0, axis= 1)\n",
    "jobs[\"power_bi\"] = jobs.apply(lambda x: 1 if \"power bi\" in x.job_description.lower() else 0, axis= 1)\n",
    "jobs[\"sql\"] = jobs.apply(lambda x: 1 if \"sql\" in x.job_description.lower() else 0, axis= 1)\n",
    "\n",
    "jobs[\"python\"].value_counts()\n",
    "jobs[\"excel\"].value_counts()\n",
    "jobs[\"tableau\"].value_counts()\n",
    "jobs[\"power_bi\"].value_counts()\n",
    "jobs[\"sql\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1711e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will import matplotlib  to beggin EDA and data visualization proccess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create a function where we can get the exact number of the x and y values in a bar graph\n",
    "def valuelabel(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i,y[i],y[i], ha = 'center',\n",
    "                  bbox = dict(facecolor = 'yellow', alpha =0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will first see visually what is the number of the jobs that require python vs the ones that dont in a stacked bar graph\n",
    "python_1 = len(jobs.loc[jobs[\"python\"]==1,\"python\"])\n",
    "sql_1 = len(jobs.loc[jobs[\"sql\"]==1,\"sql\"])\n",
    "excel_1 = len(jobs.loc[jobs[\"excel\"]==1,\"excel\"])\n",
    "tableau_1 = len(jobs.loc[jobs[\"tableau\"]==1,\"tableau\"])\n",
    "power_bi_1 = len(jobs.loc[jobs[\"power_bi\"]==1,\"power_bi\"])\n",
    "\n",
    "python_0 = len(jobs.loc[jobs[\"python\"]==0,\"python\"])\n",
    "sql_0 = len(jobs.loc[jobs[\"sql\"]==0,\"sql\"])\n",
    "excel_0 = len(jobs.loc[jobs[\"excel\"]==0,\"excel\"])\n",
    "tableau_0 = len(jobs.loc[jobs[\"tableau\"]==0,\"tableau\"])\n",
    "power_bi_0 = len(jobs.loc[jobs[\"power_bi\"]==0,\"power_bi\"])\n",
    "\n",
    "\n",
    "x = [\"python\",\"excel\",\"sql\",\"tableau\",\"power_bi\"]\n",
    "y1 = [python_1,excel_1,sql_1,tableau_1,power_bi_1]\n",
    "y2 = [python_0,excel_0,sql_0,tableau_0,power_bi_0]\n",
    "plt.bar(x,y1, color = 'b')\n",
    "plt.bar(x, y2, bottom=y1, color='r')\n",
    "valuelabel(x,y1)\n",
    "valuelabel(x,y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we could repeat this into all of the other skillset appearance but it would be a lot of redundacny and a lot of code copy and pasted\n",
    "#instead we can create a function to where we search the information wanted already graphed for looking the average salary for \n",
    "#specific jobs with specific skills\n",
    "\n",
    "def salary_info():\n",
    "    command = input(\"select job option or help for options:\").lower()\n",
    "    if command == \"help\":\n",
    "        return print(\"\"\"job options:\n",
    "        data scientist\n",
    "        data analyst\n",
    "        data engineer\n",
    "        machine learning\n",
    "        for non_data_jobs type 'n/a'\n",
    "      \n",
    "        technical skill options:\n",
    "        python\n",
    "        excel\n",
    "        sql\n",
    "        tableau\n",
    "        \"\"\")\n",
    "    elif command == \"exit\":\n",
    "        return 0\n",
    "    elif command == \"data scientist\":\n",
    "        try:\n",
    "            technical_skill = input(\"enter interest skill:\").lower()\n",
    "            skill = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==1)][\"average_salary\"].mean()\n",
    "            skill =round(skill,2)\n",
    "            non_required = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==0)][\"average_salary\"].mean()\n",
    "            non_required =round(non_required,2)\n",
    "            y= ([skill,non_required])\n",
    "            x = ([\"skill needed\",\"not required\"]) \n",
    "            plt.bar(x,y)\n",
    "            plt.ylim(80, 150)\n",
    "            valuelabel(x,y)\n",
    "            plt.show()   \n",
    "        except KeyError:\n",
    "            print(\"invalid option, try again!\")\n",
    "    elif command == \"data analyst\":\n",
    "        try:\n",
    "            technical_skill = input(\"enter interest skill:\").lower()\n",
    "            skill = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==1)][\"average_salary\"].mean()\n",
    "            skill =round(skill,2)\n",
    "            non_required = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==0)][\"average_salary\"].mean()\n",
    "            non_required =round(non_required,2)\n",
    "            y= ([skill,non_required])\n",
    "            x = ([\"skill needed\",\"not required\"]) \n",
    "            plt.bar(x,y)\n",
    "            plt.ylim(80, 150)\n",
    "            valuelabel(x,y)\n",
    "            plt.show()   \n",
    "        except KeyError:\n",
    "            print(\"invalid option, try again!\")\n",
    "    elif command == \"data engineer\":\n",
    "        try:\n",
    "            technical_skill = input(\"enter interest skill:\").lower()\n",
    "            skill = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==1)][\"average_salary\"].mean()\n",
    "            skill =round(skill,2)\n",
    "            non_required = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==0)][\"average_salary\"].mean()\n",
    "            non_required =round(non_required,2)\n",
    "            y= ([skill,non_required])\n",
    "            x = ([\"skill needed\",\"not required\"]) \n",
    "            plt.bar(x,y)\n",
    "            plt.ylim(80, 150)\n",
    "            valuelabel(x,y)\n",
    "            plt.show()   \n",
    "        except KeyError:\n",
    "            print(\"invalid option, try again!\")\n",
    "    elif command == \"machine learning\":\n",
    "        try:\n",
    "            technical_skill = input(\"enter interest skill:\").lower()\n",
    "            skill = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==1)][\"average_salary\"].mean()\n",
    "            skill =round(skill,2)\n",
    "            non_required = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==0)][\"average_salary\"].mean()\n",
    "            non_required =round(non_required,2)\n",
    "            y= ([skill,non_required])\n",
    "            x = ([\"skill needed\",\"not required\"]) \n",
    "            plt.bar(x,y)\n",
    "            plt.ylim(80, 150)\n",
    "            valuelabel(x,y)\n",
    "            plt.show()   \n",
    "        except KeyError:\n",
    "            print(\"invalid option, try again!\")\n",
    "    elif command == \"n/a\":\n",
    "        try:\n",
    "            technical_skill = input(\"enter interest skill:\").lower()\n",
    "            skill = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==1)][\"average_salary\"].mean()\n",
    "            skill =round(skill,2)\n",
    "            non_required = jobs.loc[(jobs[\"job_simp\"]==command)&(jobs[technical_skill]==0)][\"average_salary\"].mean()\n",
    "            non_required =round(non_required,2)\n",
    "            y= ([skill,non_required])\n",
    "            x = ([\"skill needed\",\"not required\"]) \n",
    "            plt.bar(x,y)\n",
    "            plt.ylim(80, 150)\n",
    "            valuelabel(x,y)\n",
    "            plt.show()   \n",
    "        except KeyError:\n",
    "            print(\"invalid option, try again!\")\n",
    "    else:\n",
    "        print(\"option not available check menu for options\")\n",
    "\n",
    "salary_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6dfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now check which type of job pays the most\n",
    "ds_mean = round(jobs.loc[jobs[\"job_simp\"]==\"data scientist\"][\"average_salary\"].mean(),2)\n",
    "da_mean = round(jobs.loc[jobs[\"job_simp\"]==\"data analyst\"][\"average_salary\"].mean(),2)\n",
    "de_mean = round(jobs.loc[jobs[\"job_simp\"]==\"data engineer\"][\"average_salary\"].mean(),2)\n",
    "ml_mean = round(jobs.loc[jobs[\"job_simp\"]==\"machine learning\"][\"average_salary\"].mean(),2)\n",
    "\n",
    "label = [\"data scientist\",\"data analyst\",\"data engineer\",\"machine learning\"]\n",
    "y = [ds_mean,da_mean,de_mean,ml_mean]\n",
    "plt.bar(label,y)\n",
    "plt.ylim(110, 130)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
